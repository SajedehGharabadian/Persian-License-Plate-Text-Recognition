{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rk20jNEE6WF",
        "outputId": "a6e47cc7-9e4e-4690-cbfd-1328170b74a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 499 (delta 0), reused 1 (delta 0), pack-reused 495\u001b[K\n",
            "Receiving objects: 100% (499/499), 3.07 MiB | 12.63 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/clovaai/deep-text-recognition-benchmark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-text-recognition-benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-UlT9ALGUqr",
        "outputId": "3c8df0c2-fe8c-4b61-987e-6c02f5e259f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyunpack\n",
        "!pip install -q patool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0AK2IYvGaES",
        "outputId": "9ae4b341-65a9-4bae-84d7-ebe4f04955b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyunpack import Archive\n",
        "Archive('/content/drive/MyDrive/License_plate_dataset/train.rar').extractall('/content/drive/MyDrive/License_plate_dataset')"
      ],
      "metadata": {
        "id": "snimNgrSGl6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Archive('/content/drive/MyDrive/License_plate_dataset/validation.rar').extractall('/content/drive/MyDrive/License_plate_dataset')"
      ],
      "metadata": {
        "id": "JUw7fRlsGpbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fire\n",
        "!pip3 install lmdb pillow torchvision nltk natsort"
      ],
      "metadata": {
        "id": "-C-U3IUpGryc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/License_plate_dataset --gtFile /content/drive/MyDrive/License_plate_dataset/gt_train.txt --outputPath /content/drive/MyDrive/License_plate_dataset/lmdb_file"
      ],
      "metadata": {
        "id": "gNlTSwvtGwPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/License_plate_dataset --gtFile /content/drive/MyDrive/License_plate_dataset/gt_validation.txt --outputPath /content/drive/MyDrive/License_plate_dataset/lmdb_file_validation"
      ],
      "metadata": {
        "id": "vs3pluuBGysV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd7Jj2FEG28Q",
        "outputId": "360fd1e4-c8d2-4ad7-f97f-ae2d7df2e786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9\n",
            "To: /content/deep-text-recognition-benchmark/TPS-ResNet-BiLSTM-Attn.pth\n",
            "100% 199M/199M [00:08<00:00, 23.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "--train_data /content/drive/MyDrive/License_plate_dataset/lmdb_file --valid_data /content/drive/MyDrive/License_plate_dataset/lmdb_file_validation \\\n",
        "--select_data / --batch_ratio 1  --batch_max_length 8  --valInterval 400 --num_iter 20000\\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6QYS7W3G5e3",
        "outputId": "d7de6514-2cd2-4416-d6cf-c6a8bfd8f0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: /content/drive/MyDrive/License_plate_dataset/lmdb_file\n",
            "opt.select_data: ['/']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/drive/MyDrive/License_plate_dataset/lmdb_file\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 19285\n",
            "num total samples of /: 19285 x 1.0 (total_data_usage_ratio) = 19285\n",
            "num samples of / per batch: 192 x 1.0 (batch_ratio) = 192\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 192 = 192\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/drive/MyDrive/License_plate_dataset/lmdb_file_validation\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 2789\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 32 100 20 1 512 256 38 8 TPS ResNet BiLSTM Attn\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (Transformation): TPS_SpatialTransformerNetwork(\n",
            "      (LocalizationNetwork): LocalizationNetwork(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): ReLU(inplace=True)\n",
            "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (10): ReLU(inplace=True)\n",
            "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (14): ReLU(inplace=True)\n",
            "          (15): AdaptiveAvgPool2d(output_size=1)\n",
            "        )\n",
            "        (localization_fc1): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
            "      )\n",
            "      (GridGenerator): GridGenerator()\n",
            "    )\n",
            "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
            "      (ConvNet): ResNet(\n",
            "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
            "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Attention(\n",
            "      (attention_cell): AttentionCell(\n",
            "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
            "        (rnn): LSTMCell(294, 256)\n",
            "      )\n",
            "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Trainable params num :  49555182\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "exp_name: TPS-ResNet-BiLSTM-Attn-Seed1111\n",
            "train_data: /content/drive/MyDrive/License_plate_dataset/lmdb_file\n",
            "valid_data: /content/drive/MyDrive/License_plate_dataset/lmdb_file_validation\n",
            "manualSeed: 1111\n",
            "workers: 4\n",
            "batch_size: 192\n",
            "num_iter: 20000\n",
            "valInterval: 400\n",
            "saved_model: \n",
            "FT: False\n",
            "adam: False\n",
            "lr: 1\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "baiduCTC: False\n",
            "select_data: ['/']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 8\n",
            "imgH: 32\n",
            "imgW: 100\n",
            "rgb: False\n",
            "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
            "sensitive: False\n",
            "PAD: False\n",
            "data_filtering_off: False\n",
            "Transformation: TPS\n",
            "FeatureExtraction: ResNet\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: Attn\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 512\n",
            "hidden_size: 256\n",
            "num_gpu: 1\n",
            "num_class: 38\n",
            "---------------------------------------\n",
            "\n",
            "[1/20000] Train loss: 3.65669, Valid loss: 3.54696, Elapsed_time: 18.00631\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.03\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.03\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "55l27710                  | kkkkkkkk                  | 0.0000\tFalse\n",
            "63b91810                  | 33222222                  | 0.0000\tFalse\n",
            "78w24710                  | 333                       | 0.0001\tFalse\n",
            "91u86663                  | 3332kkkk                  | 0.0000\tFalse\n",
            "29r51311                  | kkkkkkkk                  | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[400/20000] Train loss: 2.05179, Valid loss: 1.05510, Elapsed_time: 468.79343\n",
            "Current_accuracy : 1.685, Current_norm_ED  : 0.65\n",
            "Best_accuracy    : 1.685, Best_norm_ED     : 0.65\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "28m78498                  | 28m78498                  | 0.0024\tTrue\n",
            "42c31655                  | 22u22655                  | 0.0006\tFalse\n",
            "23n78899                  | 22m78899                  | 0.0098\tFalse\n",
            "72u75434                  | 72u75444                  | 0.0028\tFalse\n",
            "73m32455                  | 72j22255                  | 0.0035\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[800/20000] Train loss: 0.53205, Valid loss: 0.34811, Elapsed_time: 915.13397\n",
            "Current_accuracy : 77.842, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 77.842, Best_norm_ED     : 0.93\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "75u22136                  | 75u22136                  | 0.8019\tTrue\n",
            "49q59929                  | 49q59929                  | 0.8236\tTrue\n",
            "86v99863                  | 86v99863                  | 0.7933\tTrue\n",
            "17j65372                  | 17j65372                  | 0.4743\tTrue\n",
            "53u41722                  | 53u41722                  | 0.6569\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[1200/20000] Train loss: 0.25072, Valid loss: 0.33339, Elapsed_time: 1366.62227\n",
            "Current_accuracy : 75.690, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 77.842, Best_norm_ED     : 0.93\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "38v99619                  | 8899619                   | 0.0288\tFalse\n",
            "34q5623                   | 34q56223                  | 0.7816\tFalse\n",
            "16b66867                  | 16b66867                  | 0.5559\tTrue\n",
            "45h14510                  | 45h14510                  | 0.7912\tTrue\n",
            "22u69399                  | 22u69399                  | 0.6221\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[1600/20000] Train loss: 0.17559, Valid loss: 0.32111, Elapsed_time: 1812.18841\n",
            "Current_accuracy : 79.634, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "14r88216                  | 14r88416                  | 0.3719\tFalse\n",
            "79m96733                  | 79m96733                  | 0.9429\tTrue\n",
            "43w19571                  | 43w19571                  | 0.9469\tTrue\n",
            "73w12838                  | 73w12838                  | 0.9540\tTrue\n",
            "92b74716                  | 92b74716                  | 0.9545\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[2000/20000] Train loss: 0.12491, Valid loss: 0.36877, Elapsed_time: 2258.43113\n",
            "Current_accuracy : 78.308, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "15u75634                  | 15u75634                  | 0.9837\tTrue\n",
            "69r31677                  | 69r31677                  | 0.9363\tTrue\n",
            "85u24266                  | 8uu246                    | 0.0322\tFalse\n",
            "47b78199                  | 47b78199                  | 0.9598\tTrue\n",
            "66q51292                  | 66q51293                  | 0.9439\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[2400/20000] Train loss: 0.08839, Valid loss: 0.37788, Elapsed_time: 2702.22567\n",
            "Current_accuracy : 79.312, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "52q96888                  | 52996888                  | 0.1631\tFalse\n",
            "13u49                     | 13c4199                   | 0.1399\tFalse\n",
            "78r97418                  | 78r97418                  | 0.9880\tTrue\n",
            "18u6819                   | 18c68519                  | 0.2144\tFalse\n",
            "46j71619                  | 46j716                    | 0.2411\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[2800/20000] Train loss: 0.06306, Valid loss: 0.43326, Elapsed_time: 3147.78444\n",
            "Current_accuracy : 75.905, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "75r68710                  | 75r68710                  | 0.9252\tTrue\n",
            "15u79934                  | 15u79934                  | 0.8736\tTrue\n",
            "67i95110                  | 67i95110                  | 0.9549\tTrue\n",
            "76j59977                  | 76j59977                  | 0.9512\tTrue\n",
            "97j43110                  | 97j43110                  | 0.9687\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[3200/20000] Train loss: 0.04358, Valid loss: 0.43789, Elapsed_time: 3593.15146\n",
            "Current_accuracy : 77.124, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "74m83624                  | 74m83624                  | 0.9884\tTrue\n",
            "59n28555                  | 59n28555                  | 0.9248\tTrue\n",
            "46q88138                  | 46q88138                  | 0.9951\tTrue\n",
            "h1                        | h5518                     | 0.4834\tFalse\n",
            "71b86244                  | 71b86244                  | 0.9434\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[3600/20000] Train loss: 0.02918, Valid loss: 0.48754, Elapsed_time: 4036.81990\n",
            "Current_accuracy : 78.845, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "58i36488                  | 58i36488                  | 0.9926\tTrue\n",
            "86l65916                  | 86l65916                  | 0.9778\tTrue\n",
            "14q67599                  | 14q67599                  | 0.9954\tTrue\n",
            "81b3819                   | 81b28193                  | 0.9392\tFalse\n",
            "58i71355                  | 58i71355                  | 0.9688\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[4000/20000] Train loss: 0.02728, Valid loss: 0.47635, Elapsed_time: 4481.48554\n",
            "Current_accuracy : 79.383, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 79.634, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "15v92888                  | 15v92888                  | 0.9970\tTrue\n",
            "21q79699                  | 21q79699                  | 0.9900\tTrue\n",
            "13c61833                  | 13c61833                  | 0.9876\tTrue\n",
            "59i26466                  | 59i26466                  | 0.5113\tTrue\n",
            "59j28210                  | 59j28210                  | 0.9889\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[4400/20000] Train loss: 0.01011, Valid loss: 0.53083, Elapsed_time: 4927.95128\n",
            "Current_accuracy : 80.567, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 80.567, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "12m77698                  | 12m77698                  | 0.9991\tTrue\n",
            "35c58821                  | 35c58821                  | 0.9977\tTrue\n",
            "15e6548                   | 1565428                   | 0.1269\tFalse\n",
            "48m73619                  | 48m73619                  | 0.9989\tTrue\n",
            "66c11716                  | 66c11716                  | 0.9978\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[4800/20000] Train loss: 0.02929, Valid loss: 0.50354, Elapsed_time: 5379.72954\n",
            "Current_accuracy : 77.268, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 80.567, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "29i39466                  | 29i39466                  | 0.9930\tTrue\n",
            "65m11524                  | 65m11524                  | 0.9984\tTrue\n",
            "89c86574                  | 89c86574                  | 0.9906\tTrue\n",
            "38u966                    | 38u779                    | 0.8014\tFalse\n",
            "53i73891                  | 53i73891                  | 0.8975\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[5200/20000] Train loss: 0.01756, Valid loss: 0.51628, Elapsed_time: 5825.15052\n",
            "Current_accuracy : 79.670, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 80.567, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "91r2299                   | 9rr22993                  | 0.2879\tFalse\n",
            "7u11916                   | 97u11116                  | 0.3118\tFalse\n",
            "88l33199                  | 88l33199                  | 0.9787\tTrue\n",
            "17w18975                  | 17w18975                  | 0.9983\tTrue\n",
            "16r33818                  | 16r33818                  | 0.9977\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[5600/20000] Train loss: 0.00752, Valid loss: 0.55761, Elapsed_time: 6270.19755\n",
            "Current_accuracy : 81.212, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 81.212, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "57w67868                  | 57w67868                  | 0.9987\tTrue\n",
            "57m43978                  | 57m43978                  | 0.9995\tTrue\n",
            "35q47629                  | 35q47629                  | 0.9993\tTrue\n",
            "66r65688                  | 66r65688                  | 0.9973\tTrue\n",
            "39w467                    | 29w4674                   | 0.9762\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[6000/20000] Train loss: 0.00275, Valid loss: 0.58445, Elapsed_time: 6715.52035\n",
            "Current_accuracy : 80.387, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 81.212, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "73v59766                  | 73v59766                  | 0.9994\tTrue\n",
            "25n26368                  | 25n26368                  | 0.9995\tTrue\n",
            "15v92888                  | 15v92888                  | 0.9984\tTrue\n",
            "71t57322                  | 71t57322                  | 0.9973\tTrue\n",
            "85q85511                  | 85q85511                  | 0.9983\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
            "    train(opt)\n",
            "  File \"/content/deep-text-recognition-benchmark/train.py\", line 163, in train\n",
            "    preds = model(image, text[:, :-1])  # align with Attention.forward\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\", line 183, in forward\n",
            "    return self.module(*inputs[0], **module_kwargs[0])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/deep-text-recognition-benchmark/model.py\", line 90, in forward\n",
            "    prediction = self.Prediction(contextual_feature.contiguous(), text, is_train, batch_max_length=self.opt.batch_max_length)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/deep-text-recognition-benchmark/modules/prediction.py\", line 33, in forward\n",
            "    output_hiddens = torch.FloatTensor(batch_size, num_steps, self.hidden_size).fill_(0).to(device)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "E0m6G-Y7quR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder /content/demo \\\n",
        "--saved_model /content/drive/MyDrive/License_plate_dataset/save_model/best_accuracy.pth"
      ],
      "metadata": {
        "id": "N-mF4pRQHlEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23a3b59-5f95-4161-e5e5-71fdd4c2ae1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from /content/drive/MyDrive/License_plate_dataset/save_model/best_accuracy.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "/content/demo/image(50).jpg\t31m39174                 \t0.9996\n",
            "/content/demo/image(52).jpg\t77h82936                 \t0.9987\n",
            "/content/demo/image(53).jpg\t34u12574                 \t0.9976\n",
            "/content/demo/image(57).jpg\t35c68936                 \t0.9488\n",
            "/content/demo/image(64).jpg\t39r75612                 \t0.9945\n",
            "/content/demo/image(67).jpg\t47w48236                 \t0.9973\n",
            "/content/demo/image(68).jpg\t32b73112                 \t0.9996\n",
            "/content/demo/image(69).jpg\t73q75612                 \t0.4931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "En8sZEvnrHoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}